# Lecture 14 — Memory Consistency

## Roadmap

We will talk about compiler reordering, hardware reordering, and memory
consistency models.

## Context: reordering, e.g. as done by compilers.

Question: if accessing `thing.y` takes a long time, how can we speed up the
following code?

```rust
let x = thing.y;
println!("x = {}", x);
z = z + 1;
a = b + c;
```

## Hardware reordering

Hey look! The compiler can still generate code and we get what we don't expect!
But for now let's say we convince the compiler to emit the following logic.

Question: what are possible final values for `y`?

```rust
initial state: x = 0, y = 1

THREAD 1        THREAD2
y = 3;          if x == 1 {
x = 1;              y *= 2;
                }
```

Answer can be found in the [Rustonomicon
book](https://doc.rust-lang.org/nomicon/atomics.html#hardware-reordering)

To understand that, a good analogy might be: a multicore system is a bit like a
group of programmers collaborating on a project using a bizarre kind of source
control strategy (See
[here](https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/),
which also talks about memory barriers that we'll mention below)

One definition of something we might want:

* Sequentially Consistent (SeqCst)

> "... the result of any execution is the same as if the operations of all the
> processors were executed in some sequential order, and the operations of each
> individual processor appear in this sequence in the order specified by its
> program." — Leslie Lamport

## Memory consistency models

Talk about *memory barrier* or *fence*; mfence, sfence, lfence examples (x86
architecture).

* Acquire / Release

From the [Rustonomicon's
page](https://doc.rust-lang.org/nomicon/atomics.html#acquire-release)

> When thread A releases a location in memory and then thread B subsequently
> acquires the same location in memory, causality is established. Every write
> (including non-atomic and relaxed atomic writes) that happened before A's
> release will be observed by B after its acquisition.

* Relaxed

Rarely used, weakest, can be freely re-ordered, but still atomic. Can you think
of a use case? (One answer can be found in the lecture notes)

Exercise: check the runtime between `SeqCst` and `Relaxed`

```rust
/*
[dependencies]

// rustexplorer only recognize dev
// so copy release profile and make it as dev
[profile.dev]
opt-level = 3
debug = false
split-debuginfo = '...'  # Platform-specific.
debug-assertions = false
overflow-checks = false
lto = false
panic = 'unwind'
incremental = false
codegen-units = 16
rpath = false
*/

use std::{
    sync::atomic::{AtomicI64, Ordering},
    thread, time::Instant,
};

static CNT: AtomicI64 = AtomicI64::new(0);
static LARGE_CNT: usize = 10_000_000;

fn main() {
    let mut handles = vec![];
    CNT.store(0, Ordering::SeqCst);
    let start = Instant::now();
    for _ in 0..4 {
        handles.push(thread::spawn(|| {
            for _ in 0..LARGE_CNT {
                CNT.fetch_add(1, Ordering::SeqCst);
                // CNT.fetch_add(1, Ordering::Relaxed);
                // ^ Change the line and do you see any runtime difference?
                // How about on your own laptop?
            }
        }));
    }
    for h in handles {
        h.join().unwrap();
    }
    println!("{:?}", start.elapsed());
}
```

## Other

Question: memory consistency model vs. cache coherence?

*May be think of it before you read the answer below*

Answer might be found in <https://ieeexplore.ieee.org/document/546611>

By searching for "**CACHE COHERENCE PROTOCOLS**", it will tell you that there
are several definitions of cache coherence, but not all of them guarantee strong
consistency.

For the difference, as the paper says, "We view a cache coherence protocol as
simply a mechanism to propagate a newly written value. The memory consistency
model is the policy that places the bounds on when the value can be propagated
to a given processor."

## TODO: build a communication server?

The entire lecture may be wrapped as a game, where students connect to the same
server to read/write values; the server, however, uses the weird source control
strategy (see
[here](https://preshing.com/20120710/memory-barriers-are-like-source-control-operations/)
to respond the reads/writes. In the end, each student can see the changes in the
correct order, but other students see them in a different order. Then they can
inject "fence" to ensure other students see the same order as themselves see it.

# After-action report, plam, 27 Feb 2023

I did a bit of reorg in the above notes. It's still not very flipped. But I kind
of did the whole thing, and did not talk about cache coherence. Did not check
the runtime between SeqCst and Relaxed.

# After-action report, huanyi, 05Feb24

I went through everything. It appears changing `SeqCst` to `Relaxed` had no
effect on RustExplorer, but it worked on my laptop. I also talked about memory
consistency model vs. cache coherence. I think the definition from the paper is
reasonable. There was an interesting question, why compiler reording is included
in the memory consistency topic?
